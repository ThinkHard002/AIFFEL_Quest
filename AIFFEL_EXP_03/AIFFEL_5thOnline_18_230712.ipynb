{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMwWSMR0DYT/WuFq3zTeIjV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 5. 카메라 스티커앱 만들기 첫걸음\n","\n"],"metadata":{"id":"gjWTvwYMtKa1"}},{"cell_type":"markdown","source":["* 5-1. 카메라 스티커앱 만들기 첫걸음\n","* 5-2. 어떻게 만들까? 사진 준비하기\n","* 5-3. 얼굴 검출 face detection\n","* 5-4. 얼굴 랜드마크 face landmark\n","* 5-5. 스티커 적용하기\n","\n","* images (5)  \n","/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/images/hero.png\n","/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/images/king.png\n","/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/images/image.png\n","\n","* images (6)  \n","/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/images/country_boy_201203.jpeg\n","/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/images/cat-whiskers.png\n","\n","* models\n","/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/models/shape_predictor_68_face_landmarks.dat\n","\n"],"metadata":{"id":"sY2bbj-8YWTN"}},{"cell_type":"markdown","source":["## 5-2. 어떻게 만들까? 사진 준비하기"],"metadata":{"id":"4gXdpSQpX4mR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YDoy7n88ryUI"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","source":["# 필요한 패키지 import 하기\n","import os # 환경 변수나 디렉터리, 파일 등의 OS 자원을 제어할 수 있게 해주는 모듈\n","import cv2 # OpenCV라이브러리 → 컴퓨터 비전 관련 프로그래밍을 쉽게 할 수 있도록 도와주는 라이브러리\n","import matplotlib.pyplot as plt # 다양한 데이터를 많은 방법으로 도식화 할 수 있도록 하는 라이브러리\n","import numpy as np # 다차원 배열을 쉽게 처리하고 효율적으로 사용할 수 있도록 하는 라이브러리\n","import dlib # 이미지 처리 및 기계 학습, 얼굴인식 등을 할 수 있는 c++ 로 개발된 고성능의 라이브러리\n","print(\"🌫🛸\")"],"metadata":{"id":"DySTapbIsvfo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_image_path = '/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/images/image.png' # 본인 이미지가 있는 경로를 가지고 온다.\n","img_bgr = cv2.imread(my_image_path)    # OpenCV로 이미지를 불러옵니다\n","img_show = img_bgr.copy()      # 출력용 이미지를 따로 보관합니다\n","plt.imshow(img_bgr) # 이미지를 출력하기 위해 출력할 이미지를 올려준다. (실제 출력은 하지 않음)\n","plt.show() # 이미지를 출력해준다. (실제 출력)"],"metadata":{"id":"mW1kc2hduHNI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plt.imshow 이전에 RGB 이미지로 바꾸는 것을 잊지마세요.\n","img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n","plt.imshow(img_rgb) # 이미지 실제 출력하기 위해 이미지를 올려줌 (원하는 사이즈의 픽셀을 원하는 색으로 채워서 만든 그림이라고 합니다.)\n","plt.show() # 이미지 실제 출력"],"metadata":{"id":"rKfKpAwJuR8O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5-3. 얼굴 검출 face detection"],"metadata":{"id":"y6uJDL1nXh_C"}},{"cell_type":"code","source":["# detector를 선언합니다\n","detector_hog = dlib.get_frontal_face_detector() # 기본 얼굴 감지기를 반환\n","print(\"🌫🛸\")"],"metadata":{"id":"UBVcJTavumH5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n","dlib_rects = detector_hog(img_rgb, 1)   # (image, num of image pyramid)\n","print(\"🌫🛸\")"],"metadata":{"id":"SxXi6fS8yP84"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* detector_hog의 두 번째 파라미터는 이미지 피라미드의 수입니다. 이미지를 upsampling 방법을 통해 크기를 키우는 것을 이미지 피라미드라고 합니다.\n","\n","* 이미지 피라미드에서 얼굴을 다시 검출하면 작게 촬영된 얼굴을 크게 볼 수 있기 때문에 더 정확한 검출이 가능합니다.\n","\n","* 이미지 피라미드에 대한 내용은 아래 링크를 참고해 주세요.\n","\n","https://opencv-python.readthedocs.io/en/latest/doc/14.imagePyramid/imagePyramid.html\n","\n","\n","* dlib detector 는 dlib.rectangles 타입의 객체를 반환합니다. dlib.rectangles 는 dlib.rectangle 객체의 배열 형태로 이루어져 있습니다.\n","* dlib.rectangle객체는 left(), top(), right(), bottom(), height(), width() 등의 멤버 함수를 포함하고 있습니다. 더 자세한 정보는 dlib docs를 참고해주세요.\n","* Classes — dlib documentation\n","\n","http://dlib.net/python/index.html#dlib.rectangles"],"metadata":{"id":"ahroWgqLy97u"}},{"cell_type":"code","source":["# 찾은 얼굴 영역 박스 리스트\n","# 여러 얼굴이 있을 수 있습니다\n","print(dlib_rects)\n","\n","for dlib_rect in dlib_rects: # 찾은 얼굴 영역의 좌표\n","    l = dlib_rect.left() # 왼쪽\n","    t = dlib_rect.top() # 위쪽\n","    r = dlib_rect.right() # 오른쪽\n","    b = dlib_rect.bottom() # 아래쪽\n","\n","    cv2.rectangle(img_show, (l,t), (r,b), (0,255,0), 2, lineType=cv2.LINE_AA) # 시작점의 좌표와 종료점 좌표로 직각 사각형을 그림\n","\n","img_show_rgb =  cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB)\n","plt.imshow(img_show_rgb)\n","plt.show()"],"metadata":{"id":"6A3P_4CsykE4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5-4. 얼굴 랜드마크 face landmark\n"],"metadata":{"id":"WC1NOng44l3F"}},{"cell_type":"markdown","source":["\n","\n","* Dlib landmark localization\n","\n","https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/\n","\n","https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kazemi_One_Millisecond_Face_2014_CVPR_paper.pdf\n","\n","잘라진 얼굴 이미지에서 아래 68개의 이목구비 위치를 찾습니다.\n","\n","content img\n","[Dlib에 사용 되는 랜드마크 순서]\n","이 때 점의 개수는 데이터셋과 논문마다 다릅니다. 예를 들면, AFLW 데이터셋은 21개를 사용하고 ibug 300w 데이터셋은 68개를 사용합니다.\n","\n","content img\n","[Landmark 데이터셋 요약]\n","AFLW dataset\n","Dlib은 ibug 300-W 데이터셋으로 학습한 pretrained model 을 제공합니다. 학습 알고리즘은 regression tree의 앙상블 모델을 사용 했습니다. 자세한 내용이 궁금하신 분들은 2014년 CVPR (Computer Vision and Pattern Recognition) 에 발표한 논문One Millisecond Face Alignment with an Ensemble of Regression Trees 을 참고해 주세요. 오늘은 알고리즘을 이해하지 않아도 괜찮습니다.\n","\n","One Millisecond Face Alignment with an Ensemble of Regression Trees\n","Dlib의 제공되는 모델을 사용해보겠습니다. 먼저 공개되어 있는 weight file을 다운로드 받습니다. 해당 모델파일은 bz2 압축파일 형태로 제공되어 압축을 풀어준 후 사용하겠습니다.\n","\n"],"metadata":{"id":"seknn7fbYJds"}},{"cell_type":"code","source":["model_path = '/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/models/shape_predictor_68_face_landmarks.dat'\n","    # 저장한 landmark 모델의 주소를 model_path 변수에 저장\n","landmark_predictor = dlib.shape_predictor(model_path)\n","    # dlib 라이브러리의 shape_predictor 함수를 이용하여 모델을 불러옴\n","    # landmark_predictor는 RGB이미지와 dlib.rectangle를 입력 받고 dlib.full_object_detection를 반환\n","    # dlib.rectangle: 내부를 예측하는 박스\n","    # dlib.full_object_detection: 각 구성 요소의 위치와, 이미지 상의 객체의 위치를 나타냄\n","print(\"🌫🛸\")"],"metadata":{"id":"inTL5AaOCh5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list_landmarks = []\n","    # 랜드마크의 위치를 저장할 list 생성\n","\n","# 얼굴 영역 박스 마다 face landmark를 찾아냅니다\n","# face landmark 좌표를 저장해둡니다\n","for dlib_rect in dlib_rects:\n","    points = landmark_predictor(img_rgb, dlib_rect)\n","        # 모든 landmark의 위치정보를 points 변수에 저장\n","    list_points = list(map(lambda p: (p.x, p.y), points.parts()))\n","        # 각각의 landmark 위치정보를 (x,y) 형태로 변환하여 list_points 리스트로 저장\n","    list_landmarks.append(list_points)\n","        # list_landmarks에 랜드마크 리스트를 저장\n","\n","print(len(list_landmarks[0]))\n","    # 얼굴이 n개인 경우 list_landmarks는 n개의 원소를 갖고\n","    # 각 원소는 68개의 랜드마크 위치가 나열된 list\n","    # list_landmarks의 원소가 1개이므로 list_landmarks[1]을 호출하면 IndexError가 발생"],"metadata":{"id":"lsIy0kz1SJk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# list_landmarks의 원소가 1개이므로 아래 반복문은 한번만 실행됨\n","for landmark in list_landmarks:\n","    for point in landmark:\n","        cv2.circle(img_show, point, 2, (0, 255, 255), -1)\n","            # cv2.circle: OpenCV의 원을 그리는 함수\n","            # img_show 이미지 위 각각의 point에\n","            # 크기가 2이고 (0, 255, 255)색으로 내부가 채워진(-1) 원을 그림\n","            # (마지막 인수가 자연수라면 그만큼의 두께의 선으로 원이 그려짐)\n","\n","img_show_rgb = cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB)\n","    # RGB 이미지로 전환\n","plt.imshow(img_show_rgb)\n","    # 이미지를 준비\n","plt.show()\n","    # 이미지를 출력"],"metadata":{"id":"apYaB4GJSzOY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5-5. 스티커 적용하기"],"metadata":{"id":"qRU11w0WXCz5"}},{"cell_type":"code","source":["# zip() : 두 그룹의 데이터를 서로 엮어주는 파이썬의 내장 함수\n","# dlib_rects와 list_landmarks 데이터를 엮어 주었음\n","# dlib_rects : 얼굴 영역을 저장하고 있는 값\n","# → rectangles[[(345, 98) (531, 284)]]\n","# list_landmarks : 68개의 랜드마크 값 저장(이목구비 위치(x,y))\n","# → [[(368, 153), (368, 174), (371, 195), (376, 215), (382, 235), (391, 252), (404, 266), (420, 277), (441, 279), (461, 276), (480, 266), (495, 252), (508, 235), (516, 216), (520, 195), (523, 173), (524, 151), (377, 131), (386, 119), (399, 116), (413, 118), (425, 124), (454, 121), (466, 114), (481, 112), (494, 114), (503, 127), (439, 143), (438, 156), (438, 169), (437, 182), (423, 197), (431, 199), (438, 200), (446, 199), (454, 197), (391, 147), (399, 142), (409, 143), (416, 149), (408, 150), (399, 150), (464, 147), (472, 141), (482, 141), (489, 145), (482, 149), (473, 149), (411, 227), (421, 222), (432, 218), (439, 220), (446, 218), (458, 222), (471, 227), (458, 234), (446, 238), (438, 238), (431, 238), (420, 235), (415, 227), (432, 227), (439, 228), (447, 227), (466, 227), (446, 228), (438, 229), (431, 228)]]\n","\n","for dlib_rect, landmark in zip(dlib_rects, list_landmarks): # 얼굴 영역을 저장하고 있는 값과 68개의 랜드마크를 저장하고 있는 값으로 반복문 실행\n","    print (landmark[30]) # 코의 index는 30 입니다\n","    x = landmark[30][0] # 이미지에서 코 부위의 x값\n","    y = landmark[30][1] - dlib_rect.height()//2 # 이미지에서 코 부위의 y값 - 얼굴 영역의 세로를 차지하는 픽셀의 수//2 → (437, 182-(186+1//2))\n","    w = h = dlib_rect.width() # 얼굴 영역의 가로를 차지하는 픽셀의 수 (531-345+1) → max(x) - min(x) +1(픽셀의 수 이기 때문에 1을 더해줌 → 픽셀 수는 점 하나로도 1이 됨)\n","    print (f'(x,y) : ({x},{y})')\n","    print (f'(w,h) : ({w},{h})')"],"metadata":{"id":"seV-oBUuS3IJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sticker_path = os.getenv('HOME')+'/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/images/king.png' # 왕관 이미지의 경로\n","sticker_path = '/content/gdrive/MyDrive/AIFFEL_OnLine5th/AIFFEL_EXP_03/images/king.png'\n","\n","img_sticker = cv2.imread(sticker_path) # 스티커 이미지를 불러옵니다 // cv2.imread(이미지 경로) → image객체 행렬을 반환\n","img_sticker = cv2.resize(img_sticker, (w,h)) # 스티커 이미지 조정 → w,h는 얼굴 영역의 가로를 차지하는 픽셀의 수(187) // cv2.resize(image객체 행렬, (가로 길이, 세로 길이))\n","print (img_sticker.shape) # 사이즈를 조정한 왕관 이미지의 차원 확인"],"metadata":{"id":"hG_YJPoqTDf-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# x,y,w,h 모두 위에서 반복문 안에서 지정해준 값임\n","# x는 이미지에서 코 부위의 x값 = 437\n","# y는 이미지에서 코 부위의 y값 = 89\n","# w는 얼굴 영역의 가로를 차지하는 픽셀의 수 = 187\n","# h는 얼굴 영역의 가로를 차지하는 픽셀의 수 = 187\n","refined_x = x - w // 2 # 437 - (187//2) = 437-93 = 344\n","refined_y = y - h # 89-187 = -98\n","# 원본 이미지에 스티커 이미지를 추가하기 위해서 x, y 좌표를 조정합니다. 이미지 시작점은 top-left 좌표이기 때문입니다.\n","# 즉, refined_x, refined_y값에서 왕관 이미지가 시작됨\n","print (f'(x,y) : ({refined_x},{refined_y})') # 음수 발생 : 이미지 범위를 벗어남\n","# 우리는 현재 이마 자리에 왕관을 두고 싶은건데, 이마위치 - 왕관 높이를 했더니 이미지의 범위를 초과하여 음수가 나오는 것\n","# opencv는 ndarray데이터를 사용하는데, ndarray는 음수인덱스에 접근 불가하므로 스티커 이미지를 잘라 줘야 한다."],"metadata":{"id":"VISS27hDTHMs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 왕관 이미지가 이미지 밖에서 시작하지 않도록 조정이 필요함\n","# 좌표 순서가 y,x임에 유의한다. (y,x,rgb channel)\n","# 현재 상황에서는 -y 크기만큼 스티커를 crop 하고, top 의 x좌표와 y 좌표를 각각의 경우에 맞춰 원본 이미지의 경계 값으로 수정하면 아래와 같은 형식으로 나옵니다.\n","# 음수값 만큼 왕관 이미지(혹은 추후 적용할 스티커 이미지)를 자른다.\n","if refined_x < 0:\n","    img_sticker = img_sticker[:, -refined_x:]\n","    refined_x = 0\n","# 왕관 이미지를 씌우기 위해 왕관 이미지가 시작할 y좌표 값 조정\n","if refined_y < 0:\n","    img_sticker = img_sticker[-refined_y:, :] # refined_y가 -98이므로, img_sticker[98: , :]가 된다. (187, 187, 3)에서 (89, 187, 3)이 됨 (187개 중에서 98개가 잘려나감)\n","    refined_y = 0\n","\n","print (f'(x,y) : ({refined_x},{refined_y})')"],"metadata":{"id":"8LxA3aZ6WOmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sticker_area는 원본이미지에서 스티커를 적용할 위치를 crop한 이미지 입니다.\n","# 예제에서는 (344,0) 부터 (344+187, 0+89) 범위의 이미지를 의미합니다.\n","# 좌표 순서가 y,x임에 유의한다. (y,x,rgb channel)\n","# img_show[refined_y:refined_y+img_sticker.shape[0], refined_x:refined_x+img_sticker.shape[1]]\n","# img_show[0:0+89, 344:344+187]\n","# img_show[0:89, 344:531]\n","# 즉, x좌표는 344~531 / y좌표는 0~89가 됨\n","sticker_area = img_show[refined_y:refined_y+img_sticker.shape[0], refined_x:refined_x+img_sticker.shape[1]]\n","# 왕관 이미지에서 사용할 부분은 0이 아닌 색이 있는 부분을 사용합니다.\n","# 왕관 이미지에서 0이 나오는 부분은 흰색이라는 뜻, 즉 이미지가 없다는 소리임.\n","# 현재 왕관 이미지에서는 왕관과 받침대 밑의 ------ 부분이 됨\n","# 그렇기 때문에 0인 부분(이미지가 없는 부분)은 제외하고 적용\n","# sticker_area는 원본 이미지에서 스티커를 적용할 위치를 미리 잘라낸 이미지입니다.\n","# 즉, 왕관 이미지에서 왕관 이미지가 없는 부분(왕관과 받침대 밑의 ------ 부분)은 원본 이미지에서 미리 잘라놓은 sticker_area(스티커 적용할 부분 만큼 원본 이미지에서 자른 이미지)를 적용하고,\n","# 나머지 부분은 스티커로 채워주면 됨\n","# np.where는 조건에 해당하는 인덱스만 찾아서 값을 적용하는 방법이다.\n","# 아래 코드에서는 img_sticker가 0일 경우(왕관 이미지에서 왕관 부분 제외한 나머지 이미지)에는 sticker_area(원본 이미지에서 스티커를 적용할 위치를 미리 잘라낸 이미지)를 적용하고,\n","# 나머지 부분은 img_sticker(왕관 이미지)를 적용한다.\n","img_show[refined_y:refined_y+img_sticker.shape[0], refined_x:refined_x+img_sticker.shape[1]] = \\\n","    np.where(img_sticker==0,sticker_area,img_sticker).astype(np.uint8)\n","print(\"슝~\")"],"metadata":{"id":"2yUSlP5jWTzj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 왕관 이미지를 적용한 이미지를 보여준다.\n","# 얼굴 영역(7-3)과 랜드마크(7-4)를 미리 적용해놓은 img_show에 왕관 이미지를 덧붙인 이미지가 나오게 된다.)\n","plt.imshow(cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB))\n","plt.show()"],"metadata":{"id":"1NZ-g55_WaHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5lpAGTvZWeGR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. 카메라 스티커앱 만들기 첫걸음 [프로젝트]\n","\n","6-1. 프로젝트: 고양이 수염 스티커 만들기"],"metadata":{"id":"eNerzNddYfVD"}},{"cell_type":"markdown","source":["## Step 1. 스티커 구하기 or 만들기"],"metadata":{"id":"1SW5JGbmY1G8"}},{"cell_type":"code","source":[],"metadata":{"id":"G0Ns3GrAYy4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hN2NLcPkY1eM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"APPOiNbZY17B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 2. 얼굴 검출 & 랜드마크 검출 하기"],"metadata":{"id":"XpEVTV0jY2Gj"}},{"cell_type":"code","source":[],"metadata":{"id":"Pdrl4uufY2TX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VfcBHycdY2ZP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 3. 스티커 적용 위치 확인하기\n"],"metadata":{"id":"PoJIXk1_Y2l4"}},{"cell_type":"code","source":[],"metadata":{"id":"0Zp2NbyBY2xW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4WLwYPS3Y22k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 4. 스티커 적용하기"],"metadata":{"id":"RNFcBLGxY3DP"}},{"cell_type":"code","source":[],"metadata":{"id":"eeNCfbq8Y3Mg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wLi1IU7uY3Sl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 5. 문제점 찾아보기\n","\n","(1) 셀프 카메라를 다양한 각도에서 촬영하면서 스티커를 반복해서 적용해 보세요.  \n","\n","(2) 문제점이 무엇인지 최대한 자세하게 기록해 보세요. 여러분이 생각한 문제점을 해결하기 위한 방법은 분명 존재합니다!  \n","\n","오늘 만든 스티커앱에서 생각해볼 수 있는 문제점은 다음과 같습니다.  \n","\n","* 얼굴 각도에 따라 스티커가 어떻게 변해야할까요?  \n","* 멀리서 촬영하면 왜 안될까요? 옆으로 누워서 촬영하면 왜 안될까요?  \n","* 실행 속도가 중요할까요?  \n","* 스티커앱을 만들 때 정확도가 얼마나 중요할까요?  "],"metadata":{"id":"DWfXB0SFZGpa"}},{"cell_type":"code","source":[],"metadata":{"id":"sauKmuQWZUZa"},"execution_count":null,"outputs":[]}]}